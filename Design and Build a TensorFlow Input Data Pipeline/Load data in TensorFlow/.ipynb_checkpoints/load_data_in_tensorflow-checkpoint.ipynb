{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement de données dans TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook présente comment charger des fichiers de différent types dans TensorFlow 2.0.  \n",
    "Les types de fichiers traités dans le notebook sont les suivants:\n",
    "\n",
    "1. Tensor\n",
    "2. Fichier CSV\n",
    "\n",
    "Pour charger un fichier dans TensorFlow, il faut utiliser l'API `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des bibliothèques utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow vertion:  2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "print('TensorFlow vertion: ', tf.version.VERSION )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Améliorer la lecture des valeures numpy\n",
    "# (precision=3) Limiter à 3 les chiffres après la virgule\n",
    "# (suppress=True) Supprimer la notation scientifique\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger les données d'un tensor dans TensorFlow avec `.from_tensors`et `.from_tensor_slices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".from_tensors:\n",
      "[[2 3]\n",
      " [3 5]]\n",
      "\n",
      ".from_tensor_slice:\n",
      "[2 3]\n",
      "[3 5]\n"
     ]
    }
   ],
   "source": [
    "def show_data(dataset):\n",
    "    for elem in dataset:\n",
    "        print(elem.numpy())\n",
    "    \n",
    "# 2D Tensor (Rank-2)\n",
    "t1 = tf.constant([[2, 3], [3, 5]])\n",
    "# .from_tensorsCréer un dataset contenant seulement un élément\n",
    "ds1 = tf.data.Dataset.from_tensors(t)\n",
    "\n",
    "# 2D Tensor (Rank-2)\n",
    "t2 = tf.constant([[2, 3], [3, 5]])\n",
    "# .from_tensor_slices créer un dataset contennant autant d'éléments que lignes qui le composent \n",
    "ds2 = tf.data.Dataset.from_tensor_slices(t)\n",
    "\n",
    "print('.from_tensors:')\n",
    "show_data(ds1)\n",
    "print()\n",
    "print('.from_tensor_slice:')\n",
    "show_data(ds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fichier CSV\n",
    "\n",
    "1. Charger les données dans TensorFlow à partir d'un dataframe pandas.\n",
    "2. Charger les données d'un fichier csv en utilisant l'API `experimental.make_csv_datase`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser les données avant de les charger dans TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Les données utilisées sont issues des logements Parisiens disposant d'un encadrement de loyer.  \n",
    "Dans cet exemple le but est de prédire le loyer (ref) d'un appartement en fonction du nombre de pièce, époque, le quartier et la zone.\n",
    "\n",
    "Explorer les données avant de les importer dans TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_zone</th>\n",
       "      <th>id_quartier</th>\n",
       "      <th>nom_quartier</th>\n",
       "      <th>piece</th>\n",
       "      <th>epoque</th>\n",
       "      <th>meuble_txt</th>\n",
       "      <th>ref</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>annee</th>\n",
       "      <th>ville</th>\n",
       "      <th>code_grand_quartier</th>\n",
       "      <th>geo_shape</th>\n",
       "      <th>geo_point_2d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>77</td>\n",
       "      <td>Belleville</td>\n",
       "      <td>4</td>\n",
       "      <td>Avant 1946</td>\n",
       "      <td>non meublé</td>\n",
       "      <td>21.4</td>\n",
       "      <td>25.68</td>\n",
       "      <td>14.98</td>\n",
       "      <td>2020</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>7512077</td>\n",
       "      <td>{\"type\": \"Polygon\", \"coordinates\": [[[2.383226...</td>\n",
       "      <td>48.8715312006,2.38754923985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>75</td>\n",
       "      <td>Amérique</td>\n",
       "      <td>3</td>\n",
       "      <td>1971-1990</td>\n",
       "      <td>non meublé</td>\n",
       "      <td>16.7</td>\n",
       "      <td>20.04</td>\n",
       "      <td>11.69</td>\n",
       "      <td>2020</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>7511975</td>\n",
       "      <td>{\"type\": \"Polygon\", \"coordinates\": [[[2.409402...</td>\n",
       "      <td>48.8816381673,2.39544016662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>74</td>\n",
       "      <td>Pont-de-Flandre</td>\n",
       "      <td>2</td>\n",
       "      <td>1971-1990</td>\n",
       "      <td>meublé</td>\n",
       "      <td>20.2</td>\n",
       "      <td>24.24</td>\n",
       "      <td>14.14</td>\n",
       "      <td>2020</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>7511974</td>\n",
       "      <td>{\"type\": \"Polygon\", \"coordinates\": [[[2.384878...</td>\n",
       "      <td>48.8955557746,2.38477722927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>75</td>\n",
       "      <td>Amérique</td>\n",
       "      <td>1</td>\n",
       "      <td>1971-1990</td>\n",
       "      <td>meublé</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.80</td>\n",
       "      <td>16.80</td>\n",
       "      <td>2020</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>7511975</td>\n",
       "      <td>{\"type\": \"Polygon\", \"coordinates\": [[[2.409402...</td>\n",
       "      <td>48.8816381673,2.39544016662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78</td>\n",
       "      <td>Saint-Fargeau</td>\n",
       "      <td>1</td>\n",
       "      <td>Avant 1946</td>\n",
       "      <td>meublé</td>\n",
       "      <td>29.4</td>\n",
       "      <td>35.28</td>\n",
       "      <td>20.58</td>\n",
       "      <td>2020</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>7512078</td>\n",
       "      <td>{\"type\": \"Polygon\", \"coordinates\": [[[2.413813...</td>\n",
       "      <td>48.8710347391,2.40617153015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_zone  id_quartier     nom_quartier  piece      epoque  meuble_txt   ref  \\\n",
       "0       11           77       Belleville      4  Avant 1946  non meublé  21.4   \n",
       "1       13           75         Amérique      3   1971-1990  non meublé  16.7   \n",
       "2       13           74  Pont-de-Flandre      2   1971-1990      meublé  20.2   \n",
       "3       13           75         Amérique      1   1971-1990      meublé  24.0   \n",
       "4       13           78    Saint-Fargeau      1  Avant 1946      meublé  29.4   \n",
       "\n",
       "     max    min  annee  ville  code_grand_quartier  \\\n",
       "0  25.68  14.98   2020  PARIS              7512077   \n",
       "1  20.04  11.69   2020  PARIS              7511975   \n",
       "2  24.24  14.14   2020  PARIS              7511974   \n",
       "3  28.80  16.80   2020  PARIS              7511975   \n",
       "4  35.28  20.58   2020  PARIS              7512078   \n",
       "\n",
       "                                           geo_shape  \\\n",
       "0  {\"type\": \"Polygon\", \"coordinates\": [[[2.383226...   \n",
       "1  {\"type\": \"Polygon\", \"coordinates\": [[[2.409402...   \n",
       "2  {\"type\": \"Polygon\", \"coordinates\": [[[2.384878...   \n",
       "3  {\"type\": \"Polygon\", \"coordinates\": [[[2.409402...   \n",
       "4  {\"type\": \"Polygon\", \"coordinates\": [[[2.413813...   \n",
       "\n",
       "                  geo_point_2d  \n",
       "0  48.8715312006,2.38754923985  \n",
       "1  48.8816381673,2.39544016662  \n",
       "2  48.8955557746,2.38477722927  \n",
       "3  48.8816381673,2.39544016662  \n",
       "4  48.8710347391,2.40617153015  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './data/logement-encadrement-des-loyers.csv'\n",
    "df = pd.read_csv(file_path, sep=';' )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2560 entries, 0 to 2559\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id_zone              2560 non-null   int64  \n",
      " 1   id_quartier          2560 non-null   int64  \n",
      " 2   nom_quartier         2560 non-null   object \n",
      " 3   piece                2560 non-null   int64  \n",
      " 4   epoque               2560 non-null   object \n",
      " 5   meuble_txt           2560 non-null   object \n",
      " 6   ref                  2560 non-null   float64\n",
      " 7   max                  2560 non-null   float64\n",
      " 8   min                  2560 non-null   float64\n",
      " 9   annee                2560 non-null   int64  \n",
      " 10  ville                2560 non-null   object \n",
      " 11  code_grand_quartier  2560 non-null   int64  \n",
      " 12  geo_shape            2560 non-null   object \n",
      " 13  geo_point_2d         2560 non-null   object \n",
      "dtypes: float64(3), int64(5), object(6)\n",
      "memory usage: 280.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_zone</th>\n",
       "      <td>2560.0</td>\n",
       "      <td>6.662500e+00</td>\n",
       "      <td>4.225585</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_quartier</th>\n",
       "      <td>2560.0</td>\n",
       "      <td>4.050000e+01</td>\n",
       "      <td>23.096718</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.75</td>\n",
       "      <td>40.50</td>\n",
       "      <td>60.25</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piece</th>\n",
       "      <td>2560.0</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>1.118252</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref</th>\n",
       "      <td>2560.0</td>\n",
       "      <td>2.572723e+01</td>\n",
       "      <td>4.181951</td>\n",
       "      <td>14.60</td>\n",
       "      <td>22.90</td>\n",
       "      <td>25.30</td>\n",
       "      <td>28.30</td>\n",
       "      <td>39.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2560.0</td>\n",
       "      <td>3.087267e+01</td>\n",
       "      <td>5.018341</td>\n",
       "      <td>17.52</td>\n",
       "      <td>27.48</td>\n",
       "      <td>30.36</td>\n",
       "      <td>33.96</td>\n",
       "      <td>47.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2560.0</td>\n",
       "      <td>1.800906e+01</td>\n",
       "      <td>2.927365</td>\n",
       "      <td>10.22</td>\n",
       "      <td>16.03</td>\n",
       "      <td>17.71</td>\n",
       "      <td>19.81</td>\n",
       "      <td>27.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annee</th>\n",
       "      <td>2560.0</td>\n",
       "      <td>2.020000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020.00</td>\n",
       "      <td>2020.00</td>\n",
       "      <td>2020.00</td>\n",
       "      <td>2020.00</td>\n",
       "      <td>2020.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code_grand_quartier</th>\n",
       "      <td>2560.0</td>\n",
       "      <td>7.511090e+06</td>\n",
       "      <td>599.811459</td>\n",
       "      <td>7510101.00</td>\n",
       "      <td>7510595.75</td>\n",
       "      <td>7511090.50</td>\n",
       "      <td>7511585.25</td>\n",
       "      <td>7512080.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count          mean         std         min         25%  \\\n",
       "id_zone              2560.0  6.662500e+00    4.225585        1.00        3.00   \n",
       "id_quartier          2560.0  4.050000e+01   23.096718        1.00       20.75   \n",
       "piece                2560.0  2.500000e+00    1.118252        1.00        1.75   \n",
       "ref                  2560.0  2.572723e+01    4.181951       14.60       22.90   \n",
       "max                  2560.0  3.087267e+01    5.018341       17.52       27.48   \n",
       "min                  2560.0  1.800906e+01    2.927365       10.22       16.03   \n",
       "annee                2560.0  2.020000e+03    0.000000     2020.00     2020.00   \n",
       "code_grand_quartier  2560.0  7.511090e+06  599.811459  7510101.00  7510595.75   \n",
       "\n",
       "                            50%         75%         max  \n",
       "id_zone                    5.00       11.00       14.00  \n",
       "id_quartier               40.50       60.25       80.00  \n",
       "piece                      2.50        3.25        4.00  \n",
       "ref                       25.30       28.30       39.60  \n",
       "max                       30.36       33.96       47.52  \n",
       "min                       17.71       19.81       27.72  \n",
       "annee                   2020.00     2020.00     2020.00  \n",
       "code_grand_quartier  7511090.50  7511585.25  7512080.00  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer trois jeux de données\n",
    "1. Un jeux de données pour l'entrainement du model (80% des 90% de l'ensemble des données)\n",
    "2. Un jeux de données pour l'évaluation du model (20% des 90% de l'ensemble des données\n",
    "3. Un jeux de données pour réaliser des testes (10% de l'ensemble des donnée du fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_row_to_split(df, frac):\n",
    "    '''Cette fonction permet de déterminer le nombre de ligne du dataframe à retourner en fonc'''\n",
    "    percent = frac * 100\n",
    "    return round(df_sample.shape[0] * percent / 100)\n",
    "\n",
    "# Mélanger les données du dataframe\n",
    "df_sample = df.sample(frac=1, random_state=21).reset_index(drop=False)\n",
    "\n",
    "# Prendre environ 90% des données pour l'entrainement et l'évaluation du model\n",
    "row_nb = df_row_to_split(df, 0.9)\n",
    "train_eval_data = df_sample[:row_nb].drop(['index'], axis=1)\n",
    "\n",
    "# Prendre environ 10% des données pour tester du model sur de nouvelle données\n",
    "test_data = df_sample[row_nb:].drop(['index'], axis=1)\n",
    "test_data.to_csv('./data/test.csv', index=False)\n",
    "\n",
    "# Prendre 80% des données du dataframe train_eval pour l'entrainement du model\n",
    "row_nb = df_row_to_split(train_eval_data, 0.8)\n",
    "train_data = train_eval_data[:row_nb]\n",
    "train_data.to_csv('./data/train.csv', index=False)\n",
    "\n",
    "# Prendre 20% des données du dataframe train_eval pour l'évaluation du model\n",
    "eval_data = train_eval_data[row_nb:]\n",
    "eval_data.to_csv('./data/eval.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traiter les données du dataframe avant de la charger dans TensorFlow.\n",
    "\n",
    "1. Les valeurs de la colonne `epoque` ne sont pas de type continue, elles sont de type string.  \n",
    "Les données de cette colonne doivent être transformé pour pouvoir être utiliser.\n",
    "\n",
    "2. Supprimer les colonnes non utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_processed(df, features, label):\n",
    "    '''Traitement des données avant le chargement dans tensorFlow'''\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    df_processed.columns\n",
    "    \n",
    "    # Listes des noms des colonnes\n",
    "    features_label = features + label\n",
    "    # Supprimer les colonnes non utilisées\n",
    "    col_to_remove = [col_name for col_name in df_processed.columns.tolist() if col_name not in features_label]\n",
    "    \n",
    "    return df_processed.drop(col_to_remove, axis=1)\n",
    "\n",
    "def one_hot_encoding(df, col_names):\n",
    "    '''Cette fonction permet de traiter les colonnes avec des données catégoriel\n",
    "    en utilisant la methode de one-hot encoding'''\n",
    "    \n",
    "    for col_name in col_names:\n",
    "        df[col_name] = pd.Categorical(df[col_name])\n",
    "        df[col_name] = df[col_name].cat.codes\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les dataframe pandas \n",
    "\n",
    "df_train = pd.read_csv('./data/train.csv', sep=',')\n",
    "df_eval = pd.read_csv('./data/eval.csv', sep=',')\n",
    "df_test = pd.read_csv('./data/test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_zone</th>\n",
       "      <th>id_quartier</th>\n",
       "      <th>piece</th>\n",
       "      <th>epoque</th>\n",
       "      <th>ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_zone  id_quartier  piece  epoque   ref\n",
       "0        9           70      1       1  24.2\n",
       "1       10           44      2       2  28.0"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_col_name = ['ref']\n",
    "features_col_name = ['piece', 'epoque', 'id_zone', 'id_quartier'] \n",
    "\n",
    "# Pré-traitement du dataframe avant le chargement dans TensforFlow\n",
    "df_train_processed = df_processed(df_train, features_col_name, label_col_name)\n",
    "df_eval_processed = df_processed(df_eval, features_col_name, label_col_name)\n",
    "\n",
    "# Utiliser la methode du 'One Hote Encoding' pour traiter les données de type catégoriel\n",
    "df_train_processed = one_hot_encoding(df_train_processed, ['epoque'])\n",
    "df_eval_processed.epoque = one_hot_encoding(df_eval_processed, ['epoque'])\n",
    "\n",
    "df_train_processed.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charger les dataframes pandas dans TensFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(dataset, nb_row):\n",
    "    '''Cette fonction permet d'afficher les exemples d'un tensor'''\n",
    "    \n",
    "    for feat, label in dataset.take(nb_row):\n",
    "        print('Features: {}, Label: {}'.format(feat, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [ 9 70  1  1], Label: 24.2\n"
     ]
    }
   ],
   "source": [
    "# Valeures à prédire \n",
    "label_train = df_train_processed.pop(label_col_name[0])\n",
    "label_eval = df_eval_processed.pop(label_col_name[0])\n",
    "\n",
    "# Charger les données dans tensorFlow avec tf.data.Dataset.from_tensor_slices\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((df_train_processed.values, label_train.values))\n",
    "eval_dataset = tf.data.Dataset.from_tensor_slices((df_eval_processed.values, label_eval.values))\n",
    "\n",
    "show_data(train_dataset, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mélanger les données données et créer des minis batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si les données non pas déjà été mélangé:\n",
    "- `dataset.shuffle(len(df), seed=(21)).batch(nb_of_exemple)`\n",
    "\n",
    "Dans notre cas les données ont déjà été mélangé précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les minis batch sont volontairement petit pour une meilleure lisibilité des exemples\n",
    "train_data_set = train_dataset.batch(2)\n",
    "eval_data_set = eval_dataset.batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le paramètre `seed` permet de garder les données mélanger dans le même ordre et ça, peu importe le nombre de fois qu' est exécuté le code.\n",
    "\n",
    "Les ` mini batch` permettent de générer le calcul de la fonction `loss`, de calculer les `gradients` sur un ensemble d'exemples et non pas un exemple à la fois, ce qui permet d'accélérer l'entrainement et de tirer un meilleur parti du GPU qui est plus efficient pour réaliser des calculs matriciels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [[ 9 70  1  1]\n",
      " [10 44  2  2]], Label: [24.2 28. ]\n",
      "Features: [[14 76  4  3]\n",
      " [13 73  1  1]], Label: [20.1 24. ]\n"
     ]
    }
   ],
   "source": [
    "show_data(train_data_set, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charger les données d'un fichier csv en utilisant l'API `experimental.make_csv_datase`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le besoin est d'importer un ensemble important de fichiers, utiliser la fonction `tf.data.experimental.make_csv_dataset` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(file_path, **kwargs):\n",
    "    '''Cette fonction permet de charger un fichier CSV ou plusieurs fichiers dans un répertoire'''\n",
    "    \n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_pattern=file_path,\n",
    "        batch_size=3,\n",
    "        na_value=\"?\",\n",
    "        ignore_errors=True, \n",
    "        num_epochs=1,\n",
    "        **kwargs)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def show_data(dataset):\n",
    "    '''Cette fonction permet d'afficher les données contenue dans les mini batch'''\n",
    "    \n",
    "    for batch, label in dataset.take(1):\n",
    "        for key, value in batch.items():\n",
    "            print(\"{:20s}: {}\".format(key, value.numpy()))\n",
    "        print()\n",
    "        print('{:20s}: {}'.format('Labels', label.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importer les fichiers csv dans TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './data/train.csv'\n",
    "eval_file = './data/eval.csv'\n",
    "\n",
    "# Liste des colonnes à sélectioner dans le fichier\n",
    "SELECT_COLUMNS = ['id_zone','id_quartier', 'piece', 'epoque', 'ref']\n",
    "\n",
    "# Attribuer un format de données à chaque colonne (Optionel)\n",
    "DEFAULTS = [tf.int32, tf.int32, tf.int32, tf.string, tf.float32]\n",
    "\n",
    "raw_train_data = get_dataset(train_file,\n",
    "                             label_name='ref',\n",
    "                             select_columns=SELECT_COLUMNS,\n",
    "                             column_defaults=DEFAULTS)\n",
    "\n",
    "raw_eval_data = get_dataset(eval_file,\n",
    "                            label_name='ref',\n",
    "                            select_columns=SELECT_COLUMNS,\n",
    "                            column_defaults=DEFAULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_zone             : [14 13  5]\n",
      "id_quartier         : [79 50 53]\n",
      "piece               : [1 1 1]\n",
      "epoque              : [b'Apres 1990' b'Apres 1990' b'Apres 1990']\n",
      "\n",
      "Labels              : [29.  23.1 31.5]\n"
     ]
    }
   ],
   "source": [
    "show_data(raw_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-traitement des données numerique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PackNumericFeatures(object):\n",
    "    '''Cette class permet de créer un vecteur avec toutes les caratéristiques'''\n",
    "    def __init__(self, names):\n",
    "        self.names = names\n",
    "\n",
    "    def __call__(self, features, labels):\n",
    "        numeric_features = [features.pop(name) for name in self.names]\n",
    "        # Mettre les données numéric au format de type float32\n",
    "        numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
    "        # Empiler les données dans un vecteur\n",
    "        numeric_features = tf.stack(numeric_features, axis=-1)\n",
    "        # Ajouter le vecteur aux caractéristiques\n",
    "        features['numeric'] = numeric_features\n",
    "        \n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_FEATURES = ['piece', 'id_zone', 'id_quartier']\n",
    "\n",
    "# Créer un vecteur contenant les valeurs numéric qui sera ingéré par le model\n",
    "packed_train_ds = raw_train_data.map(PackNumericFeatures(NUMERIC_FEATURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoque              : [b'Apres 1990' b'1946-1970' b'1946-1970']\n",
      "numeric             : [[ 4.  9. 46.]\n",
      " [ 2.  1. 23.]\n",
      " [ 2. 11. 39.]]\n",
      "\n",
      "Labels              : [20.  30.1 25. ]\n"
     ]
    }
   ],
   "source": [
    "show_data(packed_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch, labels_batch = next(iter(packed_train_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normaliser les caratéristiques\n",
    "\n",
    "Les données de type continue doivent toujours être normalisé.   \n",
    "Normaliser les données permet d'accélérer la recherche du minima de la fonction de perte durant la descente des gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standar_scaler(data, mean, std):\n",
    "    '''\n",
    "    Cette fonction permet de normaliser les variables (data) pour qu'elles aient une moyenne nulle et une variance\n",
    "    égale à 1. Pour une variable, cela correspond à retrancher à chaque observation la moyenne (mean) de la variable et à diviser chaque observation\n",
    "    par l'écart-type (std).\n",
    "    '''\n",
    "    \n",
    "    return (data-mean) / std\n",
    "\n",
    "def mix_max_scaler(data, min_, max_):\n",
    "    '''\n",
    "    Cette fonction permet de normaliser une variable pour qu'elles evoluent en 0 et 1.\n",
    "    Pratique si besoin de probabilité.\n",
    "    '''\n",
    "    return (data-min_) / (max_ - min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>piece</th>\n",
       "      <th>id_zone</th>\n",
       "      <th>id_quartier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2048.000000</td>\n",
       "      <td>2048.000000</td>\n",
       "      <td>2048.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.492188</td>\n",
       "      <td>6.644043</td>\n",
       "      <td>40.350586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.117406</td>\n",
       "      <td>4.217204</td>\n",
       "      <td>23.005896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             piece      id_zone  id_quartier\n",
       "count  2048.000000  2048.000000  2048.000000\n",
       "mean      2.492188     6.644043    40.350586\n",
       "std       1.117406     4.217204    23.005896\n",
       "min       1.000000     1.000000     1.000000\n",
       "25%       1.000000     3.000000    20.000000\n",
       "50%       2.000000     5.000000    40.000000\n",
       "75%       3.000000    11.000000    60.000000\n",
       "max       4.000000    14.000000    80.000000"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = pd.read_csv(train_file, sep=',')[NUMERIC_FEATURES].describe()\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean            :  [ 2.4921875   6.64404297 40.35058594]\n",
      "Ecart-Type (std):  [ 2.4921875   6.64404297 40.35058594]\n",
      "Max             :  [ 4. 14. 80.]\n",
      "Min             :  [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "MEAN = np.array(desc.T['mean'])\n",
    "STD = np.array(desc.T['mean'])\n",
    "MAX = np.array(desc.T['max'])\n",
    "MIN = np.array(desc.T['min'])\n",
    "\n",
    "print('Mean            : ', MEAN)\n",
    "print('Ecart-Type (std): ', STD)\n",
    "print('Max             : ', MAX)\n",
    "print('Min             : ', MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='numeric', shape=(3,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function standar_scaler at 0x13a6fc560>, mean=array([ 2.4921875 ,  6.64404297, 40.35058594]), std=array([ 2.4921875 ,  6.64404297, 40.35058594])))]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Lier les valeures mean et std aux fonctions de normalisation\n",
    "standar_scaler = partial(standar_scaler, mean=MEAN, std=STD)\n",
    "mix_max_scaler = partial(mix_max_scaler, min_=MIN, max_=MAX)\n",
    "\n",
    "numeric_column = tf.feature_column.numeric_column('numeric',\n",
    "                                                  normalizer_fn=standar_scaler,\n",
    "                                                  shape=[len(NUMERIC_FEATURES)])\n",
    "numeric_column = [numeric_column]\n",
    "numeric_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  3., 32.],\n",
       "       [ 4., 11., 77.],\n",
       "       [ 2., 10., 44.]], dtype=float32)>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch['numeric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.59874606, -0.5484677 , -0.2069508 ],\n",
       "       [ 0.6050157 ,  0.6556184 ,  0.90827465],\n",
       "       [-0.19749217,  0.50510764,  0.09044265]], dtype=float32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normaliser les caratéristiques dans tous les mini batch\n",
    "numeric_layer = tf.keras.layers.DenseFeatures(numeric_column)\n",
    "numeric_layer(example_batch).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traiter les données catégoriel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certaines des colonnes du fichier contiennent des données catégoriel de type string,  \n",
    "Réaliser un `one-hot encoding`  en utilsant l'API `tf.feature_column` et `indicator_column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = {'epoque': ['Avant 1946', '1971-1990', 'Apres 1990', '1946-1970']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='epoque', vocabulary_list=('Avant 1946', '1971-1990', 'Apres 1990', '1946-1970'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_column = []\n",
    "\n",
    "for feature, vocab in CATEGORIES.items():\n",
    "    cat_col = (tf.feature_column.\n",
    "               categorical_column_with_vocabulary_list(key=feature, vocabulary_list=vocab))\n",
    "    \n",
    "    categorical_column.append(tf.feature_column.indicator_column(cat_col))\n",
    "    \n",
    "categorical_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "categorial_layer = tf.keras.layers.DenseFeatures(categorical_column)\n",
    "print(categorial_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combiner toutes les couches traitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.          0.          0.         -0.59874606 -0.5484677\n",
      " -0.2069508 ]\n"
     ]
    }
   ],
   "source": [
    "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_column+numeric_column)\n",
    "print(preprocessing_layer(example_batch).numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin\n",
    "\n",
    "L'étape suivante serait d'utiliser `tf.keras.Sequential` avec les données de `preprocessing_layer`.       \n",
    "Mais ce n'est pas l'objectif de ce notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources \n",
    "1. Charger les données text - lien: https://www.tensorflow.org/tutorials/load_data/text\n",
    "2. TF.text - lien:  https://www.tensorflow.org/tutorials/tensorflow_text/intro\n",
    "3. Charger des images - https://www.tensorflow.org/tutorials/load_data/images\n",
    "4. Lire les données d'un dataframe pandas - https://www.tensorflow.org/tutorials/load_data/pandas_dataframe   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
